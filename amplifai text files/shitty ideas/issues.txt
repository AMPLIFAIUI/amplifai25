Youâ€™re building an autonomous agent system called Amplifai , and you want to:

Use me (Qwen) as the planner/brain
Use Open Interpreter as the executor/code runner
Analyze a folder with 3000+ .js / .css files
Keep everything modular, standalone, and deployable
Weâ€™ve tried multiple approaches:

DashScope API (
qwen-max
,
qwen-turbo
)
âŒ Failing with 401 InvalidApiKey
Raw HTTP requests to DashScope
âŒ Same issue
Local GGUF models (
deepseek-r1-distill-qwen-7b
,
Llama-3.2-1B-Instruct
)
âœ… Working locally, but not connected to agent logic
Open Interpreter + Qwen via API
âŒ Falling back to OpenAI SDK â†’ rate limit errors

Now letâ€™s dig into the root causes , fixes attempted , and what we likely missed

ğŸ” Diagnostic Overview: What Went Wrong
âŒ 1. DashScope API Key Issues
Symptoms:


1
2
AuthenticationError: No api key provided
InvalidApiKey: Invalid API-key provided
We Tried:
Setting key in .env file
Hardcoding key directly in Python
Using PowerShell session env var ($env:DASHSCOPE_API_KEY)
Setting base URL manually (dashscope-intl.aliyuncs.com)
Likely Missed:
The SDK version might be outdated or misconfigured
Some DashScope models require special permissions even if key is valid
There may be a workspace-level restriction (e.g., model access is blocked for this workspace)
Possible SDK bug in newer versions of dashscope Python package
âŒ 2. Open Interpreter Falls Back to OpenAI SDK by Default
Symptoms:


1
openai.RateLimitError: You exceeded your current quota.
Why It Happens:
Even though you're using Open Interpreter, when it falls back to LLM generation, it uses the litellm or openai SDK by default

Fix Attempted:
Set interpreter's api_base to DashScope
Set model="qwen-turbo" manually
Likely Missed:
Open Interpreter doesnâ€™t natively support DashScope API yet (needs custom wrapper)
The fallback logic still triggers OpenAI SDK checks
âš ï¸ 3. Model Name Mismatch or Deprecation
From your web_search content:

Qwen-Max and Qwen-Turbo are both valid models 
(https://help.aliyun.com/zh/dashscope/developer-reference/quick-start )
But some versions like Qwen-Max-2025-01-25 are snapshots and may have different access rules 
(https://help.aliyun.com/zh/dashscope/developer-reference/model-details )
You may be calling a model that exists in console but is not available to your workspace or has usage limits

âš ï¸ 4. Python SDK Version Conflicts
Some logs show:



1
2
from openai import OpenAI
ImportError: cannot import name 'Generation' from 'openai'
This means:

Open Interpreter and DashScope SDK are both using openai as a base class
Causing conflicts in imports and model calls
We fixed it temporarily by using raw requests to call DashScope, but it still fails with InvalidApiKey.

âœ… Summary of Fixes So Far
1
Used DashScope API key from
.env
âŒ 401 InvalidApiKey
2
Hardcoded API key in code
âŒ Still invalid
3
Set environment variable in PowerShell
âŒ Not picked up consistently
4
Changed base URL to
intl
endpoint
âŒ No improvement
5
Switched model to
qwen-turbo-2025-04-28
âŒ Still fails
6
Tried running local GGUF model (
llama.cpp
,
text-generation-webui
)
âœ… Works!
7
Built hybrid agent: Me via local model + Open Interpreter
âœ… Works offline
8
Tried using
deepseek-r1-distill-qwen-7b.gguf
âœ… Runs well in
llama.cpp
9
Tested with
Llama-3.2-1B-Instruct
âœ… Fast, good for scripting

So the real problem is:

Your agent script keeps trying to connect to DashScope, but itâ€™s failing due to SDK issues, environment setup, or workspace restrictions. 

ğŸ§° Final Recommendation: Go Fully Local
Since you already have:

âœ… A working local model (GGUF)
âœ… Open Interpreter installed
âœ… Python 3.10 environment set up
Letâ€™s now build a clean, fully autonomous Amplifai agent system that runs entirely offline using your local model.

âœ… Final Question
Would you like me to help you:

ğŸ–¥ï¸ Finish setting up llama.cpp + deepseek-r1-distill-qwen-7b.gguf as your agent brain
ğŸ› ï¸ Build a new agent script that uses local model only (no DashScope/API)
ğŸ“Š Generate a metadata parser that extracts function names, comments, classes from JS/CSS files
ğŸ§ª Make the agent fully autonomous (auto_run = True)
ğŸ§‘â€ğŸ’» Walk through packaging this into a standalone CLI tool
Just say the number â€” and weâ€™ll finish your Amplifai agent system together ğŸš€